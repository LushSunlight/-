回应外界质疑，近日，DeepMind研究主任、前牛津大学机器学习教授Nando de Freitas在Twitter中表示，“现在一切只关乎规模！The game is over！”。他继续说道，“现在要让这些模型更大、更安全、计算效率更高、采样速度更快、内存更智能、模式更多、创新数据、在线离线．．．．．．解决这些挑战将通向AGI（通用人工智能）。”这是De Freitas回应The Next Web上的一篇评论文章，该文称“DeepMind 惊人的新‘Gato’人工智能让我担心人类永远无法实现AGI”。De Freitas回应后，The Next Web的撰稿人也不甘示弱，在文章中以下图回怼。Gato是DeepMind前几天推出的多模式、多任务、多实施的“通才”AI。Gato可以聊天、操纵真实机器人手臂堆叠块，甚至可以玩1980年代的家用视频游戏机Atari等等，其能“在广泛的环境中”执行600多项不同的任务。“这是我们目前为止最通用的智能体！”Deepmind创始人兼首席执行官Demis Hassabis也发推文支持道。De Freitas也将Gato AI描述为“多面手”，他认为扩大规模即能够创造出与人类智能相媲美的AGI。DeepMind在一篇名为“A Generalist Agent”的新研究论文中详细介绍了Gato，该论文已发布在Arxiv预印本服务器上。论文中表示，这样的智能体在扩大规模时将显示出“显著的性能提升”。但当机器学习研究员Alex Dimikas询问De Freitas认为Gato AI与通过真正的图灵测试（计算机智能的衡量标准，看人类能否区分屏幕那头是机器还是人）之间距离多远时，De Freitas也坦诚回答道，“还远得很。”判断实现AGI的一个重要标准，即AI能够在不经过训练的情况下学会做新任务，但Gato显然没有达到一些专业人士的期望。“Gato执行多项任务的能力更像是一个可以存储600种不同游戏的视频游戏机，而不是可以以600种不同方式玩的游戏，”The Next Web撰稿人Tristan Greene说，“它不是一个AGI，而是一堆经过预先训练的窄模型，整齐地捆绑在一起。”一些人认为，Gato的构建是为了完成数百个任务，但这种能力可能会影响每项任务的质量。ZDNet专栏作家Tiernan Ray写道，该智能体“实际上在几项任务上并不是那么出色”。他举例道，“它与人类进行标准聊天对话的能力同样平庸，有时会引发矛盾和荒谬的话语。”例如，当被问及法国的首都在哪里时，Gato有时会回答“马赛”，有时会回答“巴黎”。研究小组建议，这种不准确性“可能会随着进一步扩展而得到改善”。研究人员根据参数（7900万、3.64 亿和主要模型11.8 亿）比较了三种模型大小的所有基准任务平均分数，显示Gato的性能与参数数量成正比Gato只有11.8亿参数，与1750亿参数的GPT-3、5400亿参数的巨大PaLM模型等相比显得微不足道。据该团队称，这主要是由于所使用的Sawyer机器人手臂的响应时间，较大的模型会因为太慢而无法在当前硬件和当前架构上执行机器人任务。他们认为更大的Gato模型可以使用更多数据进行训练，并可能更好地执行各种任务。对当前这个Gato的表现，The Next Web的文章中毫不客气地评价称，Gato展示的AGI只不过是亚马逊的Alexa和苹果的Siri等虚拟助手，它们已经在市场上和人们的家中。除这些之外，AI领域内的一个更为根本的分歧在于AGI的实现路径。Robust.AI的创始人兼首席执行官Gary Marcus说道，“De Freitas非常清楚，不能仅仅将模型做得更大就希望获得成功。DeepMind最新推出的Gato能够在AI领域实现前所未有的跨模式壮举，但是，当您仔细观察细节时，会发现实际上仍停留在同一片不可靠的土地上——AI有智能的表现同时也有绝对的不理解。”Marcus将这种研究路径称为Alt Intelligence，“Alt Intelligence并不是要建造像人类智能的解决问题方式的机器。它是使用大量通常来自人类行为的数据，来代替智能。”“当然，深度学习的捍卫者提出‘人类也会犯错误’这样的合理观点并不少见。但任何坦率的人都会认识到，这些错误表明目前有些事情是严重错误的。如果我的任何一个孩子经常犯这样的错误，我会毫不夸张地放弃我正在做的所有其他事情，并立即将他们带到神经科医生那里。”Marcus更为直接地说道。在Marcus看来，如果我们要构建AGI，就需要向人类学习一些东西，学习其如何推理和理解物理世界，以及如何表示和获取语言和复杂概念，“不这样认为是纯粹的狂妄自大”。The Next Web的Greene表示，“我相信Gato可能是世界上最先进的多模态人工智能系统。但我也认为，DeepMind采用了与OpenAI相同的AGI死胡同，只是为了让它更具市场价值。在对通用人工智能（AGI）向往的同时，这样的AI也被视为人类的威胁，可能有意或无意地消灭人类。牛津大学人类未来研究所的Stuart Armstrong此前曾表示，AGI最终将使人类变得多余并消灭我们。他相信机器将以人类大脑无法想象的速度工作，并且将跳过与人类的交流来控制经济和金融市场、交通、医疗保健等。“由于人类语言很容易被误解，超级计算机可以将一条简单的指令解释为‘杀死所有人类’，从而让AGI‘防止人类受苦’。” Armstrong说。史蒂芬·霍金曾在去世前接受BBC采访时说道，“全面人工智能的发展可能意味着人类的终结。”De Freitas本人也在Twitter上回答AI研究人员提出的问题时表示，在开发AGI 时，“安全性至关重要”。“这可能是我们面临的最大挑战，每个人都应该考虑一下。缺乏足够的多样性也让我很担心。”在2016年的《安全中断智能体》（Safely Interruptible Agents）论文中，DeepMind研究人员概述了一个防止高级人工智能忽略关机命令的框架，其认为需要一个“红色大按钮”来防止机器完成“有害的一系列动作”。DeepMind于2010 年在伦敦成立，2014年被谷歌收购，以在2016年创建了击败人类职业围棋选手李世石的AlphaGo而闻名。2020年，该公司宣布已解决50年前的生物学问题——“蛋白质折叠问题”，了解蛋白质的氨基酸序列如何决定其3D结构。DeepMind称通过训练具有17万个已知蛋白质序列及其不同结构的神经网络，以92% 的准确率解决了这个问题。责任编辑：李墨轩