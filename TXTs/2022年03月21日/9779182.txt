原标题：加强生命科学、AI科技伦理立法研究，这份重磅文件透露哪些信息如何防止人脸识别滥用？自动驾驶如果出车祸了谁埋单？一些突破性的技术和应用，往往伴随着伦理上的争议。继国家科技伦理委员会成立之后，我国科技伦理治理又发布了标志性文件。近日，中共中央办公厅、国务院办公厅印发了《关于加强科技伦理治理的意见》（下称《意见》），从总体要求、明确科技伦理原则、健全科技伦理治理体制、加强科技伦理治理制度保障、强化科技伦理审查和监管、深入开展科技伦理教育和宣传等方面作出具体部署。《意见》提出了治理要求——伦理先行、依法依规、敏捷治理、立足国情、开放合作，同时明确了科技伦理原则，包括增进人类福祉、尊重生命权利、坚持公平公正、合理控制风险、保持公开透明。科技活动应鼓励利益相关方和社会公众合理参与，建立涉及重大、敏感伦理问题的科技活动披露机制。加强重点领域科技伦理立法研究去年12月召开的中央全面深化改革委员会第二十三次会议指出，党的十八大以来，党中央组建国家科技伦理委员会，完善治理体制机制，推动科技伦理治理取得积极进展。要坚持促进创新与防范风险相统一、制度规范与自我约束相结合，强化底线思维和风险意识，把科技伦理要求贯穿到科学研究、技术开发等科技活动全过程，覆盖到科技创新各领域，加强监测预警和前瞻研究，及时从规制上做好应对，确保科技活动风险可控。要避免把科技伦理问题泛化，努力实现科技创新高质量发展与高水平安全的良性互动。《意见》指出，制定完善科技伦理规范和标准，建立科技伦理审查和监管制度，提高科技伦理治理法治化水平，加强科技伦理理论研究。例如，“十四五”期间，重点加强生命科学、医学、人工智能等领域的科技伦理立法研究，及时推动将重要的科技伦理规范上升为国家法律法规。以人工智能为例，尽管目前AI技术还远未达到像《银翼杀手》《西部世界》等影视作品中的水平，但AI技术在带来便利的同时，也存在各种新的风险，如何协调人工智能发展与伦理治理的关系显得尤为迫切。清华大学苏世民书院院长、国家新一代人工智能治理专业委员会主任薛澜曾在接受第一财经记者专访时表示，如果人工智能的治理跟不上，不但有可能给社会带来各种风险，而且在某种程度上也会制约AI本身的发展。他告诉记者，当前人工智能治理面临的最大挑战，是我们没有一套比较成熟的体系来规制其潜在的风险，这和过去是有差别的。因为之前我们一直都在用比较成熟的技术，中国可以借鉴其他国家治理这些技术的经验。而现在不同的是，在第四次工业革命背景下，我国的人工智能技术和其他国家一样都处于发展期，所以大家都没有现成的规制体系。这样就使得我们在发展科技的同时，也在同步发展我们的规制体系。“这可能是人工智能发展面临的最大挑战。”薛澜说，在科技领域，很多技术都像硬币的两面，在带来正面效应的同时也会存在风险，而人工智能可能只是一个比较突出的领域。科研人员伦理责任《意见》提到，要完善政府科技伦理管理体制，压实创新主体科技伦理管理主体责任，发挥科技类社会团体的作用，引导科技人员自觉遵守科技伦理要求。比如，科技人员要主动学习科技伦理知识，增强科技伦理意识，自觉践行科技伦理原则，坚守科技伦理底线，发现违背科技伦理要求的行为，要主动报告、坚决抵制。科技项目（课题）负责人要严格按照科技伦理审查批准的范围开展研究，加强对团队成员和项目（课题）研究实施全过程的伦理管理，发布、传播和应用涉及科技伦理敏感问题的研究成果应当遵守有关规定、严谨审慎。就在近期，科技部公布50多起教育、医疗机构医学科研诚信案件调查处理结果，多人被终身取消科技计划项目申报资格。一位申请过多个科研项目的双一流高校教师对第一财经表示，目前从中央到地方松绑政策越来越多，但是在实操流程上还是有一些落差，因为确实有一些科研人员的作风和诚信存在问题，而信任机制是需要逐渐建立的，等这个机制建立好之后，这些申请的流程、环节可能就会更少，他们投入在科研业务上的时间也会更加充裕。责任编辑：王珊珊